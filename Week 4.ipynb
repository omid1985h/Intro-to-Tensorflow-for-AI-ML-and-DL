{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6d5a8b8",
   "metadata": {},
   "source": [
    "# Example: Horse vs Human Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7996be",
   "metadata": {},
   "source": [
    "* For this task, we will build a simple neural network to classify images of horses and humans. We’ll use the TensorFlow tf.data API for data loading and preprocessing.\n",
    "\n",
    "* Assuming you have the dataset available locally or in a directory structure like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdfa702",
   "metadata": {},
   "source": [
    "/data\n",
    "    /train\n",
    "        /horses\n",
    "        /humans\n",
    "    /test\n",
    "        /horses\n",
    "        /humans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bb1386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150\n",
    "\n",
    "# Define directories\n",
    "train_dir = '/data/train'\n",
    "test_dir = '/data/test'\n",
    "\n",
    "# Create image dataset from directories\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='binary',  # binary classification: 0 for horses, 1 for humans\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='binary',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eb0622",
   "metadata": {},
   "source": [
    "* image_dataset_from_directory: This function automatically labels images based on subdirectories (e.g., horses as class 0, humans as class 1).\n",
    "* image_size: We resize all images to 150x150 pixels for consistency.\n",
    "* batch_size: The number of images per batch. This affects how efficiently we train the model (typically 32 or 64).\n",
    "* label_mode='binary': We specify binary labels for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdabb5a9",
   "metadata": {},
   "source": [
    "* 3. Data Augmentation (Optional)\n",
    "* You can augment your training dataset by applying random transformations to the images. This can improve generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee6f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "])\n",
    "\n",
    "# Apply the augmentation only to the training dataset\n",
    "train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0321da2b",
   "metadata": {},
   "source": [
    "* RandomFlip, RandomRotation, RandomZoom: These augmentations help the model generalize better by creating slight variations in the images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb4031c",
   "metadata": {},
   "source": [
    "* 4. Prefetching for Performance\n",
    "* To improve input pipeline performance, we use prefetching. This allows data loading to happen in parallel with model training.\n",
    "* AUTOTUNE: This optimizes the number of elements loaded at a time to maximize training throughput without overloading the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8cb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601bba67",
   "metadata": {},
   "source": [
    "5. Model Creation\n",
    "\n",
    "* Conv2D and MaxPooling2D: These layers are part of the convolutional architecture commonly used in image classification tasks. They help the model learn spatial hierarchies in images.\n",
    "* The Conv2D layers use 32, 64, and 128 filters. The number of filters increases as we go deeper into the network, which helps capture more complex patterns.\n",
    "* Flatten: Converts the 2D feature maps from the convolution layers into a 1D vector to feed into the dense layers.\n",
    "* Dense(128, activation='relu'): A fully connected layer with 128 neurons, typically used to capture high-level features.\n",
    "* Dense(1, activation='sigmoid'): The final layer. Since we have a binary classification problem (horse vs human), we use:\n",
    "* Sigmoid: Outputs a probability between 0 and 1, which corresponds to a binary classification decision.\n",
    "* 1 Neuron: One output neuron for binary classification (the probability of one class; the other class is implicitly the complement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4124d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),  # Input layer (images have 3 channels for RGB)\n",
    "    \n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),  # Convolutional layer with 32 filters\n",
    "    tf.keras.layers.MaxPooling2D(),  # MaxPooling to downsample\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),  # Flatten the output of the convolutional layers\n",
    "    tf.keras.layers.Dense(128, activation='relu'),  # Dense layer with 128 neurons\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),  # Output layer (binary classification)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfcfabf",
   "metadata": {},
   "source": [
    "6. Compilation and Training\n",
    "* Adam optimizer: A commonly used optimizer for image classification tasks, combining the advantages of both RMSProp and SGD.\n",
    "* BinaryCrossentropy: This loss function is suitable for binary classification tasks. It measures the difference between the predicted probabilities and the actual class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f26f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10,\n",
    "    validation_data=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae26db5c",
   "metadata": {},
   "source": [
    "* 7. Evaluting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a99b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b6b7c4",
   "metadata": {},
   "source": [
    "### Hyperparameter Selection:\n",
    "* Number of Neurons and Layers: We chose 32, 64, and 128 filters in the convolutional layers, progressively increasing the number of neurons as we go deeper. This is common in CNNs, as deeper layers typically learn more abstract and complex features.\n",
    "\n",
    "* You can experiment with these numbers (e.g., using 256 filters or adding more layers), but be mindful of overfitting if you have limited data.\n",
    "\n",
    "* Binary Crossentropy Loss: Since this is a binary classification task (horse vs. human), we use BinaryCrossentropy. This loss function is appropriate because we’re predicting a probability (i.e., the likelihood of one class), not a multi-class output.\n",
    "\n",
    "* Sigmoid Activation: This activation is chosen for the output layer because it produces values in the range of 0 to 1, making it ideal for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceee061",
   "metadata": {},
   "outputs": [],
   "source": [
    "   Input (150x150x3)\n",
    "        │\n",
    "        ▼\n",
    "  +---------------------+    (Conv2D with 32 filters)\n",
    "  |      150x150x3      |\n",
    "  +---------------------+\n",
    "        │\n",
    "        ▼\n",
    "  +---------------------+    (MaxPooling 2x2)\n",
    "  |      75x75x32       |\n",
    "  +---------------------+\n",
    "        │\n",
    "        ▼\n",
    "  +---------------------+    (Conv2D with 64 filters)\n",
    "  |      75x75x32       |\n",
    "  +---------------------+\n",
    "        │\n",
    "        ▼\n",
    "  +---------------------+    (MaxPooling 2x2)\n",
    "  |      37x37x64       |\n",
    "  +---------------------+\n",
    "        │\n",
    "        ▼\n",
    "  +---------------------+    (Conv2D with 128 filters)\n",
    "  |      37x37x64       |\n",
    "  +---------------------+\n",
    "        │\n",
    "        ▼\n",
    "  +---------------------+    (MaxPooling 2x2)\n",
    "  |      18x18x128      |\n",
    "  +---------------------+\n",
    "        │\n",
    "        ▼\n",
    "  +---------------------+    (Flatten to 1D)\n",
    "  |      18x18x128      |\n",
    "  +---------------------+\n",
    "        │\n",
    "        ▼\n",
    "  +---------------------+    (Dense Layer with 128 neurons)\n",
    "  |     Flattened       |\n",
    "  |    (18*18*128)      |\n",
    "  +---------------------+\n",
    "        │\n",
    "        ▼\n",
    "  +---------------------+    (Output layer with 1 neuron for binary classification)\n",
    "  |      Dense (1)      |\n",
    "  +---------------------+\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695b8a34",
   "metadata": {},
   "source": [
    "* Conv2D layers: Change the depth (number of filters), but the spatial dimensions (height and width) generally stay the same unless you use a stride greater than 1.\n",
    "* MaxPooling layers: Reduce the spatial dimensions (height and width) by a factor of 2 (if using 2x2 pooling).\n",
    "* Flattening: Converts the final 3D feature map (height, width, depth) into a 1D vector.\n",
    "* Dense layers: Do not alter spatial dimensions but reduce the features into a fixed-size vector for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a11f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
